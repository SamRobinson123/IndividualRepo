{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4011ae1-f180-4375-b9d5-96888f470f69",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc67f6cd-5407-4c7c-ba7d-d2043dfb5311",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dad40bae-7aa4-4391-ae84-c2cea7e662b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from lifelines import KaplanMeierFitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077d031a-0b94-45b2-90dd-750a3b949bea",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "795e1545-223f-41a7-858a-b101a08906a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"IWC_Work_Orders_Extract.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6dcabf95-c253-4e30-8ad4-01e3af33f182",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['FUNCTIONAL_LOC'].isna() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1386c0dd-a37e-4ebc-bab0-a9402d759a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarob\\AppData\\Local\\Temp\\ipykernel_27208\\3288744948.py:2: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['EQUIP_START_UP_DATE'] = df.groupby('FUNCTIONAL_LOC')['EQUIP_START_UP_DATE'].transform(lambda group: group.ffill().bfill())\n"
     ]
    }
   ],
   "source": [
    "#filling in missing 'EQUIP_START_UP_DATE' values that already have a corresponding value based on 'FUNCTIONAL_LOC'\n",
    "df['EQUIP_START_UP_DATE'] = df.groupby('FUNCTIONAL_LOC')['EQUIP_START_UP_DATE'].transform(lambda group: group.ffill().bfill())\n",
    "#transforming date columns into datetime datatype\n",
    "df['EQUIP_START_UP_DATE'] = pd.to_datetime(df['EQUIP_START_UP_DATE'], errors='coerce')\n",
    "df['EXECUTION_START_DATE'] = pd.to_datetime(df['EXECUTION_START_DATE'])\n",
    "#creating a year column\n",
    "df['YEAR'] = df['EXECUTION_START_DATE'].dt.year\n",
    "#seperating out 'FUNCTIONAL_LOC'\n",
    "df[['SEGMENT_1', 'SEGMENT_2', 'SEGMENT_3', 'SEGMENT_4', 'SEGMENT_5', 'SEGMENT_6']] = df['FUNCTIONAL_LOC'].str.split('-', expand=True, n=5)\n",
    "#aranging dataset in ascending order of the below features\n",
    "df = df.sort_values(by=['FUNCTIONAL_LOC','EXECUTION_START_DATE','ACTUAL_START_TIME'], ascending=[True,True,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e97bf18-7c95-41da-b142-7c8ebcf6b40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean 'ACTUAL_START_TIME' by removing milliseconds (if they exist) and convert to datetime time format\n",
    "df['ACTUAL_START_TIME'] = pd.to_datetime(df['ACTUAL_START_TIME'].str.split('.').str[0], format='%H:%M:%S').dt.time\n",
    "\n",
    "#combine 'EXECUTION_START_DATE' and 'ACTUAL_START_TIME' into a single datetime column\n",
    "df['Maintenance_Start_Datetime'] = pd.to_datetime(df['EXECUTION_START_DATE'].astype(str) + ' ' + df['ACTUAL_START_TIME'].astype(str))\n",
    "\n",
    "#sort the DataFrame by 'FUNCTIONAL_LOC' and 'Maintenance_Start_Datetime'\n",
    "df = df.sort_values(by=['FUNCTIONAL_LOC', 'Maintenance_Start_Datetime'], ascending=[True, True])\n",
    "\n",
    "#create a new column to store the time until the next unplanned maintenance\n",
    "df['Time_To_Failure'] = None\n",
    "\n",
    "#loop through each machine group\n",
    "for loc, group in df.groupby('FUNCTIONAL_LOC'):\n",
    "    #create a variable to track the next unplanned maintenance date\n",
    "    next_unplanned_date = None\n",
    "\n",
    "    #loop over the rows in this group\n",
    "    for idx in reversed(group.index):\n",
    "        row = df.loc[idx]\n",
    "\n",
    "        #if the row represents an \"Unplanned\" maintenance update next_unplanned_date\n",
    "        if row['MAINTENANCE_ACTIVITY_TYPE'] == 'Unplanned':\n",
    "            if next_unplanned_date is not None:\n",
    "                #calculate the time until the next unplanned maintenance\n",
    "                time_to_failure = (next_unplanned_date - row['Maintenance_Start_Datetime']).days\n",
    "                df.at[idx, 'Time_To_Failure'] = time_to_failure\n",
    "            next_unplanned_date = row['Maintenance_Start_Datetime']\n",
    "        else:\n",
    "            #for planned maintenance, calculate the time until the next unplanned maintenance\n",
    "            if next_unplanned_date is not None:\n",
    "                time_to_failure = (next_unplanned_date - row['Maintenance_Start_Datetime']).days\n",
    "                df.at[idx, 'Time_To_Failure'] = time_to_failure\n",
    "\n",
    "#convert the new column into a integer\n",
    "df['Time_To_Failure'] = pd.to_numeric(df['Time_To_Failure'], errors='coerce').astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "789502d0-74c3-445b-8415-eb9c5bc6ffa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarob\\AppData\\Local\\Temp\\ipykernel_27208\\3225125504.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Time_To_Failure'].fillna(overall_mean, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#filter for missing values\n",
    "df_filtered = df[df['Time_To_Failure'].isna() == False]\n",
    "#find the mean of 'Time_To_Failure' for each machine group\n",
    "overall_mean = df_filtered['Time_To_Failure'].mean()\n",
    "#round it into an integer\n",
    "overall_mean = overall_mean.round()\n",
    "#fill in missing values\n",
    "df['Time_To_Failure'].fillna(overall_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8de51819-b721-4f4d-ad23-68ff0e43a5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new column to store the days since last planned maintenance\n",
    "df['Days_Since_Planned_Maintenance'] = None\n",
    "\n",
    "#loop through each machine group\n",
    "for loc, group in df.groupby('FUNCTIONAL_LOC'):\n",
    "    #track the last planned maintenance date\n",
    "    last_planned_date = None\n",
    "\n",
    "    #loop over the rows in this group\n",
    "    for idx, row in group.iterrows():\n",
    "        #if the row represents a \"Planned\" maintenance, update last_planned_date\n",
    "        if row['MAINTENANCE_ACTIVITY_TYPE'] == 'Planned':\n",
    "            last_planned_date = row['Maintenance_Start_Datetime']\n",
    "            df.at[idx, 'Days_Since_Planned_Maintenance'] = 0  #set to 0 on the day of planned maintenance\n",
    "        else:\n",
    "            #for non-planned maintenance, calculate days since the last planned maintenance\n",
    "            if last_planned_date is not None:\n",
    "                days_since = (row['Maintenance_Start_Datetime'] - last_planned_date).days\n",
    "                df.at[idx, 'Days_Since_Planned_Maintenance'] = days_since\n",
    "\n",
    "#convert the new column to integer\n",
    "df['Days_Since_Planned_Maintenance'] = pd.to_numeric(df['Days_Since_Planned_Maintenance'], errors='coerce').astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b409cbb-b94f-4958-8aaa-6ed131de691d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarob\\AppData\\Local\\Temp\\ipykernel_27208\\172671851.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Days_Since_Planned_Maintenance'].fillna(overall_mean, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#filter for missing values\n",
    "df_filtered = df[df['Days_Since_Planned_Maintenance'].isna() == False]\n",
    "#find the mean of 'Days_Since_Planned_Maintenance' for each machine group\n",
    "overall_mean = df_filtered['Days_Since_Planned_Maintenance'].mean()\n",
    "#round it into an integer\n",
    "overall_mean = overall_mean.round()\n",
    "#fill in missing values\n",
    "df['Days_Since_Planned_Maintenance'].fillna(overall_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3c746b7-3ffa-4251-b60b-05d54fe8e783",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a binary flag for \"Unplanned\" maintenance\n",
    "df['Unplanned_Flag'] = (df['MAINTENANCE_ACTIVITY_TYPE'] == 'Unplanned').astype(int)\n",
    "\n",
    "#convert 'EXECUTION_START_DATE' to datetime if it's not already\n",
    "df['EXECUTION_START_DATE'] = pd.to_datetime(df['EXECUTION_START_DATE'])\n",
    "\n",
    "#sort the DataFrame by 'FUNCTIONAL_LOC' and 'EXECUTION_START_DATE'\n",
    "df = df.sort_values(by=['FUNCTIONAL_LOC', 'EXECUTION_START_DATE'], ascending=[True, True])\n",
    "\n",
    "#define a rolling window function\n",
    "def calculate_rolling_unplanned(df, window_size):\n",
    "    return df.groupby('FUNCTIONAL_LOC')['Unplanned_Flag'].rolling(window=window_size, min_periods=1).sum().reset_index(level=0, drop=True)\n",
    "\n",
    "#calculate rolling sums for different time windows\n",
    "days_in_month = 30\n",
    "\n",
    "df['Unplanned_Rolling_12M'] = calculate_rolling_unplanned(df, window_size=12 * days_in_month)\n",
    "df['Unplanned_Rolling_6M'] = calculate_rolling_unplanned(df, window_size=6 * days_in_month)\n",
    "df['Unplanned_Rolling_1M'] = calculate_rolling_unplanned(df, window_size=1 * days_in_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "388a9466-6f63-40e6-a3c9-d8beab75f644",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a binary flag for \"Planned\" maintenance\n",
    "df['Planned_Flag'] = (df['MAINTENANCE_ACTIVITY_TYPE'] == 'Planned').astype(int)\n",
    "\n",
    "#convert 'EXECUTION_START_DATE' to datetime if it's not already\n",
    "df['EXECUTION_START_DATE'] = pd.to_datetime(df['EXECUTION_START_DATE'])\n",
    "\n",
    "#sort the DataFrame by 'FUNCTIONAL_LOC' and 'EXECUTION_START_DATE'\n",
    "df = df.sort_values(by=['FUNCTIONAL_LOC', 'EXECUTION_START_DATE'], ascending=[True, True])\n",
    "\n",
    "#define a rolling window function\n",
    "def calculate_rolling_unplanned(df, window_size):\n",
    "    return df.groupby('FUNCTIONAL_LOC')['Planned_Flag'].rolling(window=window_size, min_periods=1).sum().reset_index(level=0, drop=True)\n",
    "\n",
    "#calculate rolling sums for different time windows\n",
    "days_in_month = 30\n",
    "\n",
    "df['Planned_Rolling_12M'] = calculate_rolling_unplanned(df, window_size=12 * days_in_month)\n",
    "df['Planned_Rolling_6M'] = calculate_rolling_unplanned(df, window_size=6 * days_in_month)\n",
    "df['Planned_Rolling_1M'] = calculate_rolling_unplanned(df, window_size=1 * days_in_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4863a1c5-e8c0-4fc6-a170-5a9b5b530939",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a binary flag for each equipment occurrence\n",
    "df['Equipment_Occurrence_Flag'] = 1\n",
    "\n",
    "#group by 'FUNCTIONAL_LOC' and 'EQUIPMENT_ID', perform cumulative sum to get rolling count\n",
    "df['Cumulative_Equipment_Replacements'] = df.groupby(['FUNCTIONAL_LOC', 'EQUIPMENT_ID'])['Equipment_Occurrence_Flag'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f3f2abd-0ceb-4d7b-acd8-e24497263e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Equipment_Occurrence_Flag','YEAR','EQUIPMENT_DESC',\t'EQUIP_CAT_DESC','EQUIP_START_UP_DATE',\t'EQUIP_VALID_FROM',\t'EQUIP_VALID_TO',\n",
    "'FUNCTIONAL_LOC',\t'FUNCTIONAL_AREA_NODE_1_MODIFIED',\t'FUNCTIONAL_AREA_NODE_2_MODIFIED',\t'FUNCTIONAL_AREA_NODE_3_MODIFIED',\t'FUNCTIONAL_AREA_NODE_4_MODIFIED', 'FUNCTIONAL_AREA_NODE_5_MODIFIED',\n",
    "'MAINTENANCE_ACTIVITY_TYPE',\t'ORDER_DESCRIPTION',\t'MAINTENANCE_TYPE_DESCRIPTION','MAINTENANCE_PLAN','ORDER_ID',\t'PLANT_ID',\t'PRODUCTION_LOCATION',\t'EXECUTION_START_DATE',\t'EXECUTION_FINISH_DATE',\n",
    "'ACTUAL_START_TIME',\t'ACTUAL_FINISH_TIME',\t'SEGMENT_1',\t'SEGMENT_2',\t'SEGMENT_3',\t'SEGMENT_4',\t'SEGMENT_5',\t'SEGMENT_6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48e24949-19ca-4f3d-93eb-7b5f1e190224",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Unplanned_Rolling_12M',\t'Unplanned_Rolling_6M','Planned_Rolling_12M',\t'Planned_Rolling_6M','Equipment_Occurrence_Flag','Unplanned_Flag','Planned_Flag','YEAR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af522fa7-84d0-4871-bafa-4196945cab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unplanned = df[df['MAINTENANCE_ACTIVITY_TYPE']=='Unplanned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a7a59af-cd1a-408f-8f7d-724304cd11bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split FUNCTIONAL_LOC into multiple components based on the '-' delimiter, allowing up to 5 columns\n",
    "df_split = df_unplanned['FUNCTIONAL_LOC'].str.split('-', expand=True, n=5)\n",
    "\n",
    "# If the resulting split produces fewer than 5 columns, fill with NaN and rename accordingly\n",
    "df_split = df_split.iloc[:, :5]  # Ensure we have exactly 5 columns, adding NaN if necessary\n",
    "\n",
    "# Rename the columns (ensure we have 5 column names to match the 5 split columns)\n",
    "df_split.columns = ['Plant', 'Process', 'Subprocess', 'Product_Line', 'Machine']\n",
    "\n",
    "# Concatenate the new split columns back to the original dataframe\n",
    "df_unplanned = pd.concat([df_unplanned, df_split], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7731801c-4cee-4259-9d13-c9eda65a33f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORDER_ID</th>\n",
       "      <th>PLANT_ID</th>\n",
       "      <th>PRODUCTION_LOCATION</th>\n",
       "      <th>EXECUTION_START_DATE</th>\n",
       "      <th>EXECUTION_FINISH_DATE</th>\n",
       "      <th>ACTUAL_START_TIME</th>\n",
       "      <th>ACTUAL_FINISH_TIME</th>\n",
       "      <th>ACTUAL_WORK_IN_MINUTES</th>\n",
       "      <th>MAINTENANCE_PLAN</th>\n",
       "      <th>MAINTENANCE_ITEM</th>\n",
       "      <th>...</th>\n",
       "      <th>Time_To_Failure</th>\n",
       "      <th>Days_Since_Planned_Maintenance</th>\n",
       "      <th>Unplanned_Rolling_1M</th>\n",
       "      <th>Planned_Rolling_1M</th>\n",
       "      <th>Cumulative_Equipment_Replacements</th>\n",
       "      <th>Plant</th>\n",
       "      <th>Process</th>\n",
       "      <th>Subprocess</th>\n",
       "      <th>Product_Line</th>\n",
       "      <th>Machine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1016872</th>\n",
       "      <td>702711887</td>\n",
       "      <td>G221</td>\n",
       "      <td>SUZUKA</td>\n",
       "      <td>2021-01-16</td>\n",
       "      <td>2021-01-16</td>\n",
       "      <td>05:50:04</td>\n",
       "      <td>08:00:00.000</td>\n",
       "      <td>360.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>791</td>\n",
       "      <td>G221</td>\n",
       "      <td>CLR</td>\n",
       "      <td>A85</td>\n",
       "      <td>E06</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314204</th>\n",
       "      <td>700108001</td>\n",
       "      <td>G221</td>\n",
       "      <td>SUZUKA</td>\n",
       "      <td>2017-07-25</td>\n",
       "      <td>2017-07-25</td>\n",
       "      <td>07:00:00</td>\n",
       "      <td>07:00:00.000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>343</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>G221</td>\n",
       "      <td>PRD</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973849</th>\n",
       "      <td>700702956</td>\n",
       "      <td>G221</td>\n",
       "      <td>SUZUKA</td>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>07:00:00</td>\n",
       "      <td>08:50:09.000</td>\n",
       "      <td>270.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>245</td>\n",
       "      <td>146</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>G221</td>\n",
       "      <td>PRD</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928119</th>\n",
       "      <td>701239235</td>\n",
       "      <td>G221</td>\n",
       "      <td>SUZUKA</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>08:00:00.000</td>\n",
       "      <td>480.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>392</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>G221</td>\n",
       "      <td>PRD</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314206</th>\n",
       "      <td>701241831</td>\n",
       "      <td>G221</td>\n",
       "      <td>SUZUKA</td>\n",
       "      <td>2019-03-06</td>\n",
       "      <td>2019-03-06</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>08:00:00.000</td>\n",
       "      <td>480.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>393</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>G221</td>\n",
       "      <td>PRD</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ORDER_ID PLANT_ID PRODUCTION_LOCATION EXECUTION_START_DATE  \\\n",
       "1016872  702711887     G221              SUZUKA           2021-01-16   \n",
       "314204   700108001     G221              SUZUKA           2017-07-25   \n",
       "973849   700702956     G221              SUZUKA           2018-07-03   \n",
       "928119   701239235     G221              SUZUKA           2019-03-05   \n",
       "314206   701241831     G221              SUZUKA           2019-03-06   \n",
       "\n",
       "        EXECUTION_FINISH_DATE ACTUAL_START_TIME ACTUAL_FINISH_TIME  \\\n",
       "1016872            2021-01-16          05:50:04       08:00:00.000   \n",
       "314204             2017-07-25          07:00:00       07:00:00.000   \n",
       "973849             2018-07-03          07:00:00       08:50:09.000   \n",
       "928119             2019-03-05          08:00:00       08:00:00.000   \n",
       "314206             2019-03-06          08:00:00       08:00:00.000   \n",
       "\n",
       "         ACTUAL_WORK_IN_MINUTES MAINTENANCE_PLAN  MAINTENANCE_ITEM  ...  \\\n",
       "1016872                   360.0              NaN               NaN  ...   \n",
       "314204                     45.0              NaN               NaN  ...   \n",
       "973849                    270.0              NaN               NaN  ...   \n",
       "928119                    480.0              NaN               NaN  ...   \n",
       "314206                    480.0              NaN               NaN  ...   \n",
       "\n",
       "        Time_To_Failure Days_Since_Planned_Maintenance Unplanned_Rolling_1M  \\\n",
       "1016872              40                              4                  1.0   \n",
       "314204              343                             10                  1.0   \n",
       "973849              245                            146                  2.0   \n",
       "928119                1                            392                  3.0   \n",
       "314206                2                            393                  4.0   \n",
       "\n",
       "        Planned_Rolling_1M Cumulative_Equipment_Replacements Plant Process  \\\n",
       "1016872               29.0                               791  G221     CLR   \n",
       "314204                 0.0                                 1  G221     PRD   \n",
       "973849                 1.0                                 3  G221     PRD   \n",
       "928119                 1.0                                 4  G221     PRD   \n",
       "314206                 1.0                                 5  G221     PRD   \n",
       "\n",
       "        Subprocess Product_Line  Machine  \n",
       "1016872        A85          E06     None  \n",
       "314204        None         None     None  \n",
       "973849        None         None     None  \n",
       "928119        None         None     None  \n",
       "314206        None         None     None  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unplanned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeacfa8-7a8c-4c8a-8110-2de7efd64288",
   "metadata": {},
   "source": [
    "## Train Radnom Forrest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70a96d9-2148-40ab-a492-60eefde52d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after filtering: Counter({317: 3120, 478: 1049, 382: 1043, 390: 848, 316: 794, 327: 782, 475: 773, 391: 684, 452: 579, 509: 487, 397: 354, 550: 327, 405: 316, 321: 312, 474: 289, 453: 284, 393: 273, 66: 262, 281: 259, 406: 235, 462: 226, 392: 221, 69: 219, 64: 210, 309: 209, 552: 198, 63: 198, 404: 197, 516: 195, 515: 171, 402: 167, 746: 160, 277: 151, 476: 148, 588: 147, 331: 146, 68: 138, 415: 136, 477: 134, 481: 133, 542: 124, 563: 121, 541: 120, 429: 118, 279: 117, 269: 116, 289: 116, 448: 115, 520: 111, 519: 110, 333: 104, 522: 102, 234: 101, 357: 96, 65: 93, 285: 90, 290: 83, 335: 81, 487: 81, 414: 79, 110: 77, 134: 77, 416: 74, 446: 73, 140: 72, 394: 70, 430: 68, 590: 67, 631: 64, 503: 63, 294: 63, 380: 62, 549: 60, 556: 59, 362: 59, 457: 59, 227: 54, 196: 53, 326: 53, 119: 52, 525: 50, 70: 50, 489: 50, 517: 48, 407: 48, 514: 47, 461: 46, 423: 43, 447: 41, 363: 39, 358: 39, 359: 38, 420: 38, 544: 36, 286: 36, 662: 35, 141: 34, 328: 34, 554: 33, 488: 33, 643: 33, 366: 33, 591: 32, 157: 31, 133: 31, 413: 31, 547: 30, 422: 30, 454: 30, 399: 29, 400: 28, 592: 27, 365: 27, 36: 27, 553: 26, 386: 26, 278: 25, 530: 25, 412: 25, 740: 25, 229: 24, 361: 24, 282: 24, 486: 23, 260: 23, 374: 22, 97: 22, 641: 22, 292: 21, 288: 21, 367: 21, 301: 21, 313: 20, 408: 20, 240: 20, 464: 20, 492: 19, 129: 19, 428: 19, 427: 19, 302: 19, 280: 18, 348: 18, 562: 18, 576: 18, 61: 18, 469: 18, 490: 18, 131: 17, 53: 17, 417: 17, 419: 17, 303: 17, 523: 16, 230: 16, 385: 16, 485: 16, 104: 16, 451: 16, 67: 16, 325: 16, 568: 16, 186: 15, 378: 15, 107: 15, 480: 15, 56: 15, 55: 15, 738: 15, 98: 15, 103: 15, 46: 15, 291: 15, 510: 14, 483: 14, 670: 14, 572: 14, 235: 14, 355: 14, 356: 14, 539: 14, 652: 14, 663: 14, 197: 13, 181: 13, 158: 13, 162: 13, 334: 13, 388: 13, 208: 13, 342: 12, 518: 12, 546: 12, 369: 12, 557: 12, 54: 12, 581: 12, 287: 12, 231: 12, 71: 12, 565: 12, 465: 12, 295: 12, 276: 11, 527: 11, 659: 11, 733: 11, 14: 11, 318: 11, 332: 11, 42: 11, 48: 11, 268: 11, 431: 11, 499: 10, 144: 10, 551: 10, 373: 10, 442: 10, 742: 10, 311: 10, 384: 10, 73: 10, 307: 10, 395: 10, 347: 9, 122: 9, 320: 9, 381: 9, 57: 9, 645: 9, 744: 9, 19: 9, 368: 9, 101: 9, 314: 9, 398: 9, 300: 9, 432: 9, 574: 8, 155: 8, 185: 8, 589: 8, 433: 8, 458: 8, 655: 8, 438: 8, 160: 8, 272: 8, 628: 8, 706: 8, 621: 8, 684: 8, 330: 8, 538: 8, 99: 8, 33: 8, 37: 8, 472: 8, 85: 8, 360: 8, 283: 8, 45: 8, 596: 8, 90: 8, 82: 8, 455: 8, 653: 8, 353: 7, 748: 7, 1: 7, 500: 7, 504: 7, 379: 7, 199: 7, 484: 7, 603: 7, 689: 7, 224: 7, 41: 7, 540: 7, 4: 7, 579: 7, 598: 7, 81: 7, 200: 6, 108: 6, 137: 6, 502: 6, 319: 6, 636: 6, 153: 6, 178: 6, 195: 6, 375: 6, 376: 6, 377: 6, 126: 6, 686: 6, 687: 6, 434: 6, 482: 6, 611: 6, 696: 6, 616: 6, 688: 6, 634: 6, 383: 6, 411: 6, 100: 6, 102: 6, 640: 6, 473: 6, 296: 6, 512: 6, 735: 5, 349: 5, 121: 5, 513: 5, 496: 5, 372: 5, 681: 5, 713: 5, 610: 5, 712: 5, 435: 5, 578: 5, 9: 5, 329: 5, 410: 5, 587: 5, 62: 5, 31: 5, 418: 5, 665: 5, 421: 5, 668: 5, 51: 5, 456: 5, 424: 5, 672: 5, 304: 5, 298: 5})\n",
      "Class distribution after SMOTE: Counter({281: 2184, 316: 2184, 317: 2184, 550: 2184, 478: 2184, 327: 2184, 309: 2184, 452: 2184, 662: 2184, 321: 2184, 65: 2184, 42: 2184, 382: 2184, 390: 2184, 542: 2184, 331: 2184, 448: 2184, 197: 2184, 285: 2184, 134: 2184, 397: 2184, 475: 2184, 68: 2184, 489: 2184, 393: 2184, 157: 2184, 423: 2184, 99: 2184, 286: 2184, 588: 2184, 386: 2184, 517: 2184, 394: 2184, 402: 2184, 358: 2184, 488: 2184, 740: 2184, 399: 2184, 516: 2184, 391: 2184, 738: 2184, 362: 2184, 69: 2184, 279: 2184, 415: 2184, 64: 2184, 420: 2184, 55: 2184, 746: 2184, 544: 2184, 668: 2184, 101: 2184, 462: 2184, 477: 2184, 556: 2184, 357: 2184, 522: 2184, 499: 2184, 413: 2184, 37: 2184, 333: 2184, 453: 2184, 289: 2184, 540: 2184, 406: 2184, 576: 2184, 631: 2184, 366: 2184, 307: 2184, 465: 2184, 186: 2184, 503: 2184, 481: 2184, 490: 2184, 392: 2184, 509: 2184, 63: 2184, 474: 2184, 416: 2184, 446: 2184, 326: 2184, 66: 2184, 140: 2184, 290: 2184, 641: 2184, 141: 2184, 515: 2184, 628: 2184, 234: 2184, 421: 2184, 563: 2184, 107: 2184, 404: 2184, 706: 2184, 380: 2184, 90: 2184, 541: 2184, 603: 2184, 458: 2184, 405: 2184, 659: 2184, 487: 2184, 400: 2184, 283: 2184, 476: 2184, 303: 2184, 520: 2184, 119: 2184, 461: 2184, 381: 2184, 523: 2184, 514: 2184, 294: 2184, 483: 2184, 368: 2184, 301: 2184, 70: 2184, 269: 2184, 554: 2184, 454: 2184, 110: 2184, 196: 2184, 552: 2184, 519: 2184, 361: 2184, 549: 2184, 292: 2184, 224: 2184, 280: 2184, 302: 2184, 229: 2184, 97: 2184, 414: 2184, 268: 2184, 429: 2184, 587: 2184, 276: 2184, 277: 2184, 61: 2184, 374: 2184, 562: 2184, 486: 2184, 596: 2184, 313: 2184, 553: 2184, 314: 2184, 655: 2184, 385: 2184, 430: 2184, 85: 2184, 589: 2184, 419: 2184, 447: 2184, 598: 2184, 590: 2184, 335: 2184, 424: 2184, 131: 2184, 359: 2184, 126: 2184, 502: 2184, 652: 2184, 365: 2184, 457: 2184, 122: 2184, 412: 2184, 330: 2184, 162: 2184, 670: 2184, 388: 2184, 318: 2184, 538: 2184, 407: 2184, 643: 2184, 181: 2184, 539: 2184, 464: 2184, 291: 2184, 687: 2184, 129: 2184, 527: 2184, 611: 2184, 1: 2184, 422: 2184, 383: 2184, 735: 2184, 408: 2184, 300: 2184, 363: 2184, 645: 2184, 525: 2184, 98: 2184, 133: 2184, 334: 2184, 282: 2184, 260: 2184, 500: 2184, 367: 2184, 328: 2184, 153: 2184, 684: 2184, 185: 2184, 469: 2184, 663: 2184, 53: 2184, 137: 2184, 230: 2184, 56: 2184, 41: 2184, 235: 2184, 14: 2184, 451: 2184, 355: 2184, 712: 2184, 104: 2184, 372: 2184, 591: 2184, 572: 2184, 438: 2184, 384: 2184, 733: 2184, 518: 2184, 513: 2184, 48: 2184, 373: 2184, 103: 2184, 4: 2184, 744: 2184, 369: 2184, 227: 2184, 347: 2184, 57: 2184, 100: 2184, 360: 2184, 568: 2184, 546: 2184, 547: 2184, 45: 2184, 428: 2184, 356: 2184, 696: 2184, 640: 2184, 398: 2184, 36: 2184, 653: 2184, 621: 2184, 427: 2184, 492: 2184, 484: 2184, 485: 2184, 565: 2184, 81: 2184, 557: 2184, 278: 2184, 19: 2184, 442: 2184, 54: 2184, 46: 2184, 455: 2184, 578: 2184, 295: 2184, 636: 2184, 510: 2184, 616: 2184, 395: 2184, 311: 2184, 592: 2184, 208: 2184, 102: 2184, 410: 2184, 349: 2184, 434: 2184, 688: 2184, 742: 2184, 574: 2184, 342: 2184, 379: 2184, 67: 2184, 158: 2184, 431: 2184, 144: 2184, 325: 2184, 411: 2184, 579: 2184, 504: 2184, 530: 2184, 200: 2184, 332: 2184, 298: 2184, 272: 2184, 482: 2184, 435: 2184, 71: 2184, 155: 2184, 195: 2184, 512: 2184, 417: 2184, 713: 2184, 378: 2184, 689: 2184, 551: 2184, 199: 2184, 62: 2184, 231: 2184, 296: 2184, 581: 2184, 672: 2184, 377: 2184, 178: 2184, 33: 2184, 287: 2184, 288: 2184, 108: 2184, 9: 2184, 433: 2184, 240: 2184, 472: 2184, 160: 2184, 496: 2184, 432: 2184, 320: 2184, 329: 2184, 686: 2184, 634: 2184, 304: 2184, 748: 2184, 418: 2184, 348: 2184, 480: 2184, 376: 2184, 375: 2184, 73: 2184, 610: 2184, 681: 2184, 121: 2184, 456: 2184, 473: 2184, 31: 2184, 51: 2184, 82: 2184, 319: 2184, 353: 2184, 665: 2184})\n"
     ]
    }
   ],
   "source": [
    "# Necessary Imports\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import Counter\n",
    "\n",
    "# Step 1: Clean the data by dropping rows with missing EQUIPMENT_DESC\n",
    "df_with_desc = df_unplanned.dropna(subset=['EQUIPMENT_DESC'])\n",
    "df_missing_desc = df_unplanned[df_unplanned['EQUIPMENT_DESC'].isna()]\n",
    "\n",
    "# Step 2: Define the correct categorical columns\n",
    "categorical_columns = ['Plant', 'Process', 'Subprocess', 'Product_Line', 'Machine']\n",
    "\n",
    "# Step 3: One-Hot Encode the categorical columns\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "X_encoded = encoder.fit_transform(df_with_desc[categorical_columns])\n",
    "\n",
    "# Step 4: Label encode the target variable (EQUIPMENT_DESC)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(df_with_desc['EQUIPMENT_DESC'])\n",
    "\n",
    "# Step 5: Remove classes with fewer than 5 instances (to avoid SMOTE issues)\n",
    "class_counts = Counter(y_encoded)\n",
    "valid_classes = [cls for cls, count in class_counts.items() if count >= 5]\n",
    "\n",
    "# Filter out rows corresponding to classes with fewer than 5 instances\n",
    "mask = [y in valid_classes for y in y_encoded]\n",
    "X_encoded_filtered = X_encoded[mask]\n",
    "y_encoded_filtered = y_encoded[mask]\n",
    "\n",
    "# Step 6: Check distribution of the classes after filtering\n",
    "class_distribution = Counter(y_encoded_filtered)\n",
    "print(f\"Class distribution after filtering: {class_distribution}\")\n",
    "\n",
    "# Step 7: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded_filtered, y_encoded_filtered, test_size=0.3, random_state=42, stratify=y_encoded_filtered\n",
    ")\n",
    "\n",
    "# Step 8: Dynamically set k_neighbors based on the smallest class size in the training set\n",
    "train_class_distribution = Counter(y_train)\n",
    "smallest_class_count = min(train_class_distribution.values())\n",
    "\n",
    "# Set k_neighbors to a minimum value of 1 if the smallest class has fewer samples\n",
    "k_neighbors_value = max(1, min(5, smallest_class_count - 1))  # Ensure k_neighbors <= smallest class size\n",
    "\n",
    "# Step 9: Apply SMOTE to balance the classes in the training set\n",
    "smote = SMOTE(random_state=42, k_neighbors=k_neighbors_value)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 10: Check the distribution after SMOTE\n",
    "print(f\"Class distribution after SMOTE: {Counter(y_train_smote)}\")\n",
    "\n",
    "# Step 11: Train the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52ce370-b239-458c-9b5f-9ebf351fed80",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ded36db-38c5-44f3-8e8e-5ad2edf17ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 12: Get filtered target names\n",
    "filtered_target_names = label_encoder.inverse_transform(valid_classes)\n",
    "\n",
    "# Step 13: Make predictions on the test set and evaluate the model\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Ensure the target names match the filtered classes\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred, target_names=filtered_target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8b598a-cd44-467e-b0b4-072af92376d5",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8c6d83-df31-4993-9637-16c87b724f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 14: Prepare the missing data for prediction\n",
    "X_missing_encoded = encoder.transform(df_missing_desc[categorical_columns])\n",
    "\n",
    "# Step 15: Use the model to predict the missing EQUIPMENT_DESC values\n",
    "y_missing_pred = rf_classifier.predict(X_missing_encoded)\n",
    "\n",
    "# Step 16: Convert the predictions back to the original EQUIPMENT_DESC values\n",
    "predicted_descriptions = label_encoder.inverse_transform(y_missing_pred)\n",
    "\n",
    "# Step 17: Fill the missing EQUIPMENT_DESC values in the original dataframe\n",
    "df_unplanned.loc[df_unplanned['EQUIPMENT_DESC'].isna(), 'EQUIPMENT_DESC'] = predicted_descriptions\n",
    "\n",
    "# Final dataframe with filled EQUIPMENT_DESC values\n",
    "print(df_unplanned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34f2d2b-b197-4cb2-bc92-2e9ca823d3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the column names in the df_unplanned dataframe\n",
    "print(df_unplanned.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3bf24e-dbec-47fb-a44e-08d54b5260a9",
   "metadata": {},
   "source": [
    "## Time To Failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29781bf5-d1a0-485a-af2e-97a5b1a39856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the EXECUTION_FINISH_DATE is in datetime format\n",
    "df_unplanned['EXECUTION_FINISH_DATE'] = pd.to_datetime(df_unplanned['EXECUTION_FINISH_DATE'])\n",
    "\n",
    "# Sort the dataframe by EQUIPMENT_DESC and EXECUTION_FINISH_DATE\n",
    "df_unplanned = df_unplanned.sort_values(by=['EQUIPMENT_DESC', 'EXECUTION_FINISH_DATE'])\n",
    "\n",
    "# Create the TIME_TO_FAILURE column\n",
    "df_unplanned['TIME_TO_FAILURE'] = df_unplanned.groupby('EQUIPMENT_DESC')['EXECUTION_FINISH_DATE'].diff().dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc0a6b4-64e3-47d3-bd11-1cb40e22153e",
   "metadata": {},
   "source": [
    "## Splitting By Plant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaacdfb-2145-48b9-82dc-ac3af51de4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataframe by 'PRODUCTION_LOCATION'\n",
    "df_unplanned_MONZA = df_unplanned[df_unplanned['PRODUCTION_LOCATION'] == \"MONZA\"]\n",
    "df_unplanned_ROMA = df_unplanned[df_unplanned['PRODUCTION_LOCATION'] == \"ROMA\"]\n",
    "df_unplanned_COTA = df_unplanned[df_unplanned['PRODUCTION_LOCATION'] == \"COTA\"]\n",
    "df_unplanned_SILVERSTONE = df_unplanned[df_unplanned['PRODUCTION_LOCATION'] == \"SILVERSTONE\"]\n",
    "df_unplanned_MONACO = df_unplanned[df_unplanned['PRODUCTION_LOCATION'] == \"MONACO\"]\n",
    "df_unplanned_SUZUKA = df_unplanned[df_unplanned['PRODUCTION_LOCATION'] == \"SUZUKA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd345d66-8dac-4d09-98a2-274aec45a745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
